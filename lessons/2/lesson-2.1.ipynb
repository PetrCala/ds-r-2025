{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d202f82",
   "metadata": {},
   "source": [
    "# Part 2, Lesson 1: Databases, SQL & R\n",
    "**Author:** Your Name  \n",
    "**Date:** Block Lecture (4 hours)\n",
    "\n",
    "# Part 2 – Lesson 1: Advanced Databases & SQL in R\n",
    "\n",
    "Welcome to the **second part** of our course! In this first **4-hour** block, we’ll dive deeper into **databases**, **SQL**, and how to integrate them seamlessly into your R workflow. By the end of this lesson, you should understand:\n",
    "\n",
    "- When and why to store data in a **database** vs. flat files.\n",
    "- How to connect R to a local or remote **SQL database** (using `DBI` + `RSQLite` and notes on MySQL/PostgreSQL).\n",
    "- Best practices for **querying**, **inserting**, and **updating** data in a relational database.\n",
    "- Basic database design concepts (e.g., primary keys, foreign keys, indexing).\n",
    "- Strategies for **ETL** (Extract, Transform, Load) workflows in journalistic or research contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8648b7",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. **Why Databases?**\n",
    "2. **Setting Up R for Database Connections**\n",
    "3. **Creating & Managing a Local SQLite Database**\n",
    "4. **SQL Essentials Refresher**\n",
    "5. **Advanced Query Examples & Joins**\n",
    "6. **Importing / Exporting Large Data**\n",
    "7. **Remote Databases & Practical Considerations**\n",
    "8. **Mini ETL Workflow**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26c9a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Why Databases?\n",
    "\n",
    "In previous lessons, we mainly worked with **CSV** or Excel files. Flat files are fine for small datasets but can become unwieldy when:\n",
    "\n",
    "- Data is **large** or frequently updated.\n",
    "- Multiple datasets need to be **linked** via common keys.\n",
    "- We require **complex queries** or want to optimize data retrieval.\n",
    "\n",
    "A **relational database** (e.g., SQLite, MySQL, PostgreSQL) is structured, optimized for queries, and supports ACID properties. For journalists, this can be crucial when handling large public datasets (e.g., repeated FOIA requests, election data, etc.).\n",
    "\n",
    "> **Key concepts**:\n",
    "\n",
    "- **Tables** (like sheets, but with strict schemas).\n",
    "- **Primary keys** (unique row identifier).\n",
    "- **Foreign keys** (relation to another table’s primary key).\n",
    "- **Indexes** (speed up queries on certain columns).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6916e811",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Setting Up R for Database Connections\n",
    "\n",
    "R provides two main avenues:\n",
    "\n",
    "1. **`DBI` + `RSQLite`** (or `RMariaDB` for MySQL, `RPostgres` for PostgreSQL, etc.): a general interface for working with databases.\n",
    "2. **`sqldf`**: simpler but primarily for querying data frames as if they were tables.\n",
    "\n",
    "In a professional setting, `DBI` is more flexible and robust. Let’s install/load the packages we need:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed5883",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# install.packages(\"DBI\")\n",
    "# install.packages(\"RSQLite\")\n",
    "# install.packages(\"dplyr\")  # For demonstration\n",
    "\n",
    "library(DBI)\n",
    "library(RSQLite)\n",
    "library(dplyr) # We'll combine SQL & dplyr if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ea337",
   "metadata": {},
   "source": [
    "### Potential Packages for Other SQL Databases\n",
    "\n",
    "- **MySQL**: `RMariaDB` or `RMySQL`.\n",
    "- **PostgreSQL**: `RPostgres`.\n",
    "- **Microsoft SQL Server**: Various ODBC-based connectors or `odbc` package.\n",
    "\n",
    "> **Instructor Note**: For the sake of this lesson, we’ll use **SQLite** since it’s file-based and easy for demonstration. The same commands generally apply to MySQL/Postgres with minor changes in the connection details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bbc137",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Creating & Managing a Local SQLite Database\n",
    "\n",
    "We’ll create an **in-memory** database first, then we’ll demonstrate creating a **file-based** SQLite database.\n",
    "\n",
    "### 3.1 In-Memory Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44c8ff",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create an in-memory SQLite database\n",
    "con <- dbConnect(SQLite(), \":memory:\")\n",
    "\n",
    "# We'll create a sample table from a built-in dataset (mtcars)\n",
    "df_mtcars <- mtcars %>%\n",
    "  mutate(car_name = row.names(mtcars)) %>%\n",
    "  select(car_name, everything())\n",
    "\n",
    "# Write the data frame to the DB as a new table 'cars'\n",
    "dbWriteTable(con, \"cars\", df_mtcars)\n",
    "\n",
    "# Let's list the tables in our in-memory DB\n",
    "dbListTables(con)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632db1fe",
   "metadata": {},
   "source": [
    "### 3.2 Querying the Table\n",
    "\n",
    "We can use `dbGetQuery()` to run standard SQL commands:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59ed1d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# SELECT only cars with 6 cylinders, sorted by mpg descending\n",
    "query_result <- dbGetQuery(con, \"SELECT car_name, cyl, mpg\n",
    "                           FROM cars\n",
    "                           WHERE cyl = 6\n",
    "                           ORDER BY mpg DESC;\")\n",
    "query_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcb56c",
   "metadata": {},
   "source": [
    "> **Note**: The in-memory database will disappear once we close the connection or end the session.\n",
    "\n",
    "### 3.3 File-Based SQLite Database\n",
    "\n",
    "To persist data:\n",
    "\n",
    "```r\n",
    "con_file <- dbConnect(SQLite(), \"my_database.sqlite\")\n",
    "# Now we can do the same dbWriteTable, dbGetQuery, etc.\n",
    "dbWriteTable(con_file, \"cars\", df_mtcars)\n",
    "dbListTables(con_file)\n",
    "dbDisconnect(con_file)  # Always disconnect when done!\n",
    "```\n",
    "\n",
    "This will create a **my_database.sqlite** file in your working directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16b67c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. SQL Essentials Refresher\n",
    "\n",
    "Even if we covered SQL in previous lessons, let’s recap key statements:\n",
    "\n",
    "- **`SELECT ... FROM ...`**: basic query.\n",
    "- **`WHERE ...`**: filtering.\n",
    "- **`JOIN`** clauses: combine related tables.\n",
    "- **`INSERT`, `UPDATE`, `DELETE`**: modifying data.\n",
    "- **`CREATE TABLE`, `DROP TABLE`, `ALTER TABLE`**: schema changes.\n",
    "\n",
    "### 4.1 Creating a Table via SQL\n",
    "\n",
    "Instead of `dbWriteTable`, we can run raw SQL to create an empty table:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE employees (\n",
    "  emp_id INTEGER PRIMARY KEY,\n",
    "  name TEXT NOT NULL,\n",
    "  department TEXT,\n",
    "  salary REAL\n",
    ");\n",
    "```\n",
    "\n",
    "We then **INSERT** rows. Let’s demonstrate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6943ae",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# We'll reuse our in-memory connection 'con'\n",
    "# 1) Create an 'employees' table\n",
    "dbExecute(con, \"DROP TABLE IF EXISTS employees;\") # Clean slate\n",
    "dbExecute(con, \"CREATE TABLE employees (\n",
    "                 emp_id INTEGER PRIMARY KEY,\n",
    "                 name TEXT NOT NULL,\n",
    "                 department TEXT,\n",
    "                 salary REAL\n",
    "               );\")\n",
    "\n",
    "# 2) Insert rows\n",
    "dbExecute(con, \"INSERT INTO employees (name, department, salary)\n",
    "             VALUES ('Alice', 'Sales', 50000),\n",
    "                    ('Bob', 'Marketing', 60000),\n",
    "                    ('Carla', 'IT', 70000);\")\n",
    "\n",
    "# 3) Check results\n",
    "dbGetQuery(con, \"SELECT * FROM employees;\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a329c",
   "metadata": {},
   "source": [
    "### 4.2 Updating & Deleting\n",
    "\n",
    "```r\n",
    "# Update Bob's salary\n",
    "dbExecute(con, \"UPDATE employees SET salary = 65000 WHERE name = 'Bob';\")\n",
    "# Remove Carla\n",
    "dbExecute(con, \"DELETE FROM employees WHERE name = 'Carla';\")\n",
    "\n",
    "# Check again\n",
    "dbGetQuery(con, \"SELECT * FROM employees;\")\n",
    "```\n",
    "\n",
    "These operations become powerful in large-scale data manipulation. However, always remember **transaction** safety and **backups** for production databases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fb2cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Advanced Query Examples & Joins\n",
    "\n",
    "### 5.1 JOIN Basics\n",
    "\n",
    "**Joins** let us combine multiple tables based on **key columns**. Let’s create a second table, `departments`, to store department info:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ffdf79",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Create 'departments' table\n",
    "dbExecute(con, \"DROP TABLE IF EXISTS departments;\")\n",
    "dbExecute(con, \"CREATE TABLE departments (\n",
    "                 dept_name TEXT PRIMARY KEY,\n",
    "                 location  TEXT\n",
    "               );\")\n",
    "\n",
    "# 2) Insert rows\n",
    "dbExecute(con, \"INSERT INTO departments (dept_name, location)\n",
    "             VALUES ('Sales', 'Building A'),\n",
    "                    ('Marketing', 'Building B'),\n",
    "                    ('IT', 'Annex 1');\")\n",
    "\n",
    "# 3) Let's do a LEFT JOIN on employees -> departments\n",
    "joined_query <- dbGetQuery(\n",
    "  con,\n",
    "  \"SELECT e.name, e.department, e.salary, d.location\n",
    "   FROM employees e\n",
    "   LEFT JOIN departments d\n",
    "   ON e.department = d.dept_name;\"\n",
    ")\n",
    "\n",
    "joined_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112ec17",
   "metadata": {},
   "source": [
    "> **Tip**: We can also do **`INNER JOIN`** (only matching records), **`RIGHT JOIN`**, or **`FULL OUTER JOIN`** (though SQLite doesn’t have a direct full outer join, we can simulate it).\n",
    "\n",
    "### 5.2 Aggregation & Group By\n",
    "\n",
    "Let’s compute average salary per department:\n",
    "\n",
    "```sql\n",
    "SELECT department, AVG(salary) AS avg_salary\n",
    "FROM employees\n",
    "GROUP BY department;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b2c0e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dbGetQuery(con, \"SELECT department, AVG(salary) AS avg_salary\n",
    "             FROM employees\n",
    "             GROUP BY department;\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d83e4be",
   "metadata": {},
   "source": [
    "> **Exercise**: Combine knowledge from previous parts.\n",
    "\n",
    "1. Insert more employees with different salaries.\n",
    "2. Do a grouped query by `department` with `COUNT(*)` and `AVG(salary)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd5ea6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Importing / Exporting Large Data\n",
    "\n",
    "Databases shine with **large** datasets. In R:\n",
    "\n",
    "1. You can **bulk insert** large CSV files using `dbWriteTable` or custom scripts.\n",
    "2. Export from DB to CSV with `dbGetQuery` and `write.csv`.\n",
    "\n",
    "### Example: Writing a Large Data Frame\n",
    "\n",
    "```r\n",
    "dbWriteTable(con, \"big_table\", big_df)\n",
    "```\n",
    "\n",
    "If you have memory constraints, consider chunked approaches or use the DB’s **import** utilities (like `sqlite3` command-line or MySQL’s `LOAD DATA INFILE`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de8541",
   "metadata": {},
   "source": [
    "### Combining dplyr & Databases\n",
    "\n",
    "The **`dplyr`** package integrates with `DBI` to let you write code like:\n",
    "\n",
    "```r\n",
    "library(dplyr)\n",
    "tbl_con <- tbl(con, \"employees\")  # reference a remote table\n",
    "tbl_con %>%\n",
    "  filter(salary > 55000) %>%\n",
    "  arrange(desc(salary)) %>%\n",
    "  collect()  # pulls data back into R\n",
    "```\n",
    "\n",
    "This is often called **dbplyr** (the `dplyr` backend for databases). It translates your R code into **SQL** behind the scenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093a0ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Remote Databases & Practical Considerations\n",
    "\n",
    "1. **Authentication**: You’ll typically need a **username** and **password** to connect to MySQL/Postgres. For example:\n",
    "   ```r\n",
    "   # Example for MySQL\n",
    "   library(RMariaDB)\n",
    "   con_mysql <- dbConnect(MariaDB(),\n",
    "                         user = \"myuser\",\n",
    "                         password = \"mypassword\",\n",
    "                         host = \"dbserver.example.com\",\n",
    "                         dbname = \"mydb\")\n",
    "   ```\n",
    "2. **Security**: For journalism projects on sensitive data, ensure your connections are **encrypted** (SSL/TLS). Avoid storing passwords in scripts.\n",
    "3. **Schema Management**: Larger projects may require designing multiple normalized tables, or using migrations for schema changes.\n",
    "4. **Performance**: Index frequently queried columns. For instance,\n",
    "   ```sql\n",
    "   CREATE INDEX idx_salary ON employees (salary);\n",
    "   ```\n",
    "   This speeds up queries filtering by `salary`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2ce41",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Mini ETL Workflow\n",
    "\n",
    "Let’s outline a short end-to-end scenario:\n",
    "\n",
    "1. **Extract**: We have a raw CSV with employee data (`raw_employees.csv`).\n",
    "2. **Transform**: Clean column names, fix missing salaries, unify department naming.\n",
    "3. **Load**: Insert into a new table in our SQLite database.\n",
    "4. **Query**: Summaries or merges with other tables.\n",
    "\n",
    "### Example Code (Pseudocode)\n",
    "\n",
    "```r\n",
    "# 1) Extract\n",
    "raw_df <- read_csv(\"raw_employees.csv\")\n",
    "\n",
    "# 2) Transform\n",
    "clean_df <- raw_df %>%\n",
    "  janitor::clean_names() %>%                # optional: consistent col naming\n",
    "  mutate(\n",
    "    department = str_to_title(department),  # unify naming\n",
    "    salary = ifelse(is.na(salary), 40000, salary) # fill missing with 40k\n",
    "  )\n",
    "\n",
    "# 3) Load into DB\n",
    "dbWriteTable(con, \"clean_employees\", clean_df)\n",
    "\n",
    "# 4) Query\n",
    "res <- dbGetQuery(\n",
    "  con,\n",
    "  \"SELECT department, AVG(salary) AS avg_salary\n",
    "   FROM clean_employees\n",
    "   GROUP BY department;\"\n",
    ")\n",
    "\n",
    "res\n",
    "```\n",
    "\n",
    "> **Practical**: For very large datasets, consider chunked reads/writes or direct DB import tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba622e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap-Up & Next Steps\n",
    "\n",
    "In this 4-hour lesson, you’ve learned:\n",
    "\n",
    "- Why and when to use **databases** (scalability, complex queries, multi-table linking).\n",
    "- Connecting R to **SQLite** (and references for MySQL/Postgres).\n",
    "- Core SQL statements (SELECT, JOIN, GROUP BY, INSERT, UPDATE, etc.).\n",
    "- Basic **ETL** patterns for real-world data.\n",
    "\n",
    "**Next Lesson** (Part 2, Lesson 2) might cover:\n",
    "\n",
    "- More advanced **SQL** concepts (window functions, subqueries) or\n",
    "- Database design (normalization, advanced indexing, foreign key constraints) or\n",
    "- Combining R-based analyses with dashboards (e.g., R Shiny or other front-ends) for data storytelling.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **R for Data Science** (Hadley Wickham) – for `dplyr/dbplyr` usage.\n",
    "- **Database Design** courses or tutorials for deeper schema architecture.\n",
    "- **SQLBolt** or **W3Schools** – quick references for SQL syntax.\n",
    "- **Databases for Journalists** guides (e.g., from NICAR, IRE) for practical insights.\n",
    "\n",
    "Feel free to explore, experiment, and build small demonstration databases as you become more comfortable with SQL in R!\n",
    "\n",
    "# End of Part 2, Lesson 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
